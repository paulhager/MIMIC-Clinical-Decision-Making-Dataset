{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.min_rows', 200)\n",
    "pd.set_option('display.expand_frame_repr', True)\n",
    "\n",
    "base_mimic = ''\n",
    "base_new = \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.dataset import load_data, extract_info, extract_hadm_ids, extract_hadm_ids_filter_cc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pathologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "reload = True\n",
    "\n",
    "if reload:\n",
    "    admissions_df, transfers_df, diag_icd, procedures_df, discharge_df, radiology_report_df, radiology_report_details_df, lab_events_df, microbiology_df = load_data(base_mimic)\n",
    "    admissions_df.to_csv(join(base_mimic, 'hosp', 'ClinicalBenchmark', 'admissions.csv'), index=False)\n",
    "    transfers_df.to_csv(join(base_mimic, 'hosp', 'ClinicalBenchmark', 'transfers.csv'), index=False)\n",
    "    diag_icd.to_csv(join(base_mimic, 'hosp', 'ClinicalBenchmark', 'diagnoses_icd.csv'), index=False)\n",
    "    procedures_df.to_csv(join(base_mimic, 'hosp', 'ClinicalBenchmark', 'procedures_icd.csv'), index=False)\n",
    "    discharge_df.to_csv(join(base_mimic, 'hosp', 'ClinicalBenchmark', 'discharge_notes.csv'), index=False)\n",
    "    radiology_report_df.to_csv(join(base_mimic, 'hosp', 'ClinicalBenchmark', 'radiology_reports.csv'), index=False)\n",
    "    radiology_report_details_df.to_csv(join(base_mimic, 'hosp', 'ClinicalBenchmark', 'radiology_report_details.csv'), index=False)\n",
    "    lab_events_df.to_csv(join(base_mimic, 'hosp', 'ClinicalBenchmark', 'labevents.csv'), index=False)\n",
    "    microbiology_df.to_csv(join(base_mimic, 'hosp', 'ClinicalBenchmark', 'microbiologyevents.csv'), index=False)\n",
    "else:\n",
    "    admissions_df = pd.read_csv(join(base_mimic, 'hosp', 'ClinicalBenchmark', 'admissions.csv'))\n",
    "    transfers_df = pd.read_csv(join(base_mimic, 'hosp', 'ClinicalBenchmark', 'transfers.csv'))\n",
    "    diag_icd = pd.read_csv(join(base_mimic, 'hosp', 'ClinicalBenchmark', 'diagnoses_icd.csv'))\n",
    "    procedures_df = pd.read_csv(join(base_mimic, 'hosp', 'ClinicalBenchmark', 'procedures_icd.csv'))\n",
    "    discharge_df = pd.read_csv(join(base_mimic, 'hosp', 'ClinicalBenchmark', 'discharge_notes.csv'))\n",
    "    radiology_report_df = pd.read_csv(join(base_mimic, 'hosp', 'ClinicalBenchmark', 'radiology_reports.csv'))\n",
    "    radiology_report_details_df = pd.read_csv(join(base_mimic, 'hosp', 'ClinicalBenchmark', 'radiology_report_details.csv'))\n",
    "    lab_events_df = pd.read_csv(join(base_mimic, 'hosp', 'ClinicalBenchmark', 'labevents.csv'))\n",
    "    microbiology_df = pd.read_csv(join(base_mimic, 'hosp', 'ClinicalBenchmark', 'microbiologyevents.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendicitis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab all hadm_ids with appendicitis\n",
    "app_hadm_ids = extract_hadm_ids('acute appendicitis', diag_icd, discharge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_hadm_info, app_hadm_info_clean = extract_info(app_hadm_ids, 'appendicitis', ['acute appendicitis', 'appendicitis', 'appendectomy'],\n",
    "                                                             discharge_df, admissions_df, transfers_df,lab_events_df, microbiology_df, radiology_report_df, radiology_report_details_df,\n",
    "                                                             diag_icd, procedures_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cholecystitis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholec_hadm_ids = extract_hadm_ids('acute cholecystitis', diag_icd, discharge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholec_hadm_info, cholec_hadm_info_clean = extract_info(cholec_hadm_ids, 'cholecystitis', ['acute cholecystitis', 'cholecystitis', 'cholecystostomy'], discharge_df, admissions_df, transfers_df,lab_events_df, microbiology_df, radiology_report_df, radiology_report_details_df,\n",
    "                                                             diag_icd, procedures_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pancreatitis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pancr_hadm_ids = extract_hadm_ids('acute pancreatitis', diag_icd, discharge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pancr_hadm_info, pancr_hadm_info_clean = extract_info(pancr_hadm_ids, 'pancreatitis', ['acute pancreatitis', 'pancreatitis', 'pancreatectomy'],\n",
    "                                                             discharge_df, admissions_df, transfers_df,lab_events_df, microbiology_df, radiology_report_df, radiology_report_details_df,\n",
    "                                                             diag_icd, procedures_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diverticulitis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divert_hadm_ids = extract_hadm_ids('diverticulitis', diag_icd, discharge_df, diag_counts=30, cc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divert_hadm_info, divert_hadm_info_clean = extract_info(divert_hadm_ids, 'diverticulitis', ['acute diverticulitis', 'diverticulitis'],\n",
    "                                                             discharge_df, admissions_df, transfers_df,lab_events_df, microbiology_df, radiology_report_df, radiology_report_details_df,\n",
    "                                                             diag_icd, procedures_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for First Diag and Dr Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from utils.nlp import extract_primary_diagnosis\n",
    "\n",
    "all_pathos = ['appendicitis', 'cholecystitis', 'pancreatitis', 'diverticulitis']\n",
    "\n",
    "dr_eval = {}\n",
    "\n",
    "# randomly sampled 20 cases from each patho\n",
    "dr_eval['appendicitis'] = [20414022, 20921058, 21528320, 22360162, 23101737, 23459798, 23472780, 23553042, 24613821, 25579760, 25731420, 26064146, 27022057, 27260340, 28174867, 28466255, 29080331, 29468247, 29646721, 29815898]\n",
    "dr_eval['cholecystitis'] = [20491815, 22023307, 22386848, 22825632, 23322902, 24642301, 24646115, 25643992, 26014747, 26146550, 26286187, 26354137, 26679345, 26983655, 27286714, 28342261, 28862495, 29573603, 29580001, 29723478]\n",
    "dr_eval['pancreatitis'] = [20275938, 20464014, 20804346, 21238215, 21285450, 21849575, 22778345, 23507935, 23869693, 24338433, 24571788, 24706695, 25693057, 25706907, 25779570, 26086670, 26351914, 27875265, 29037588, 29413431]\n",
    "dr_eval['diverticulitis'] = [20348908, 20754081, 21177686, 21233315, 21793374, 21906103, 22631597, 24009412, 24188879, 25568418, 25682814, 26581302, 27371462, 27794752, 27989275, 28678157, 28967154, 29137933, 29270681, 29781321]\n",
    "dr_eval['gastritis'] = [23541137, 25942424, 27148050, 29661958, 29405818]\n",
    "dr_eval['urinary_tract_infection'] = [23228674, 21812195, 28441616, 26600738, 27795432]\n",
    "dr_eval['esophageal_reflux'] = [27209421, 22004397, 27318752, 27297450, 29649502]\n",
    "dr_eval['hernia'] = [28020857, 24364147, 21309128, 26512162, 26027327]\n",
    "\n",
    "# Manual corrections after case review. These _ids have multiple diagnoses of our abdominal pathologies and are thus too inspecific\n",
    "multi_diag_ids = [26769588, 24309551, 20525915, 23074436]\n",
    "\n",
    "id_difficulty = {}\n",
    "for patho, hadm_info in zip(['appendicitis', 'cholecystitis', 'pancreatitis', 'diverticulitis'],\n",
    "                            [app_hadm_info_clean, cholec_hadm_info_clean, pancr_hadm_info_clean, divert_hadm_info_clean]):\n",
    "    first_diag_ids = []\n",
    "    for p in hadm_info:\n",
    "        if p in multi_diag_ids:\n",
    "            continue\n",
    "        dd = hadm_info[p]['Discharge Diagnosis']\n",
    "        dd = dd.lower()\n",
    "        first_diag = extract_primary_diagnosis(dd)\n",
    "        if first_diag and patho in first_diag.lower():\n",
    "            first_diag_ids.append(p)\n",
    "    \n",
    "    id_difficulty[patho] = {'first_diag': first_diag_ids, 'dr_eval': dr_eval[patho]}\n",
    "    print(f\"There are {len(first_diag_ids)} {patho} cases with first diagnosis out of {len(hadm_info)} total cases\")\n",
    "    print()\n",
    "\n",
    "id_difficulty['gastritis'] = {}\n",
    "id_difficulty['gastritis']['dr_eval'] = dr_eval['gastritis']\n",
    "\n",
    "id_difficulty['urinary_tract_infection'] = {}\n",
    "id_difficulty['urinary_tract_infection']['dr_eval'] = dr_eval['urinary_tract_infection']\n",
    "\n",
    "id_difficulty['esophageal_reflux'] = {}\n",
    "id_difficulty['esophageal_reflux']['dr_eval'] = dr_eval['esophageal_reflux']\n",
    "\n",
    "id_difficulty['hernia'] = {}\n",
    "id_difficulty['hernia']['dr_eval'] = dr_eval['hernia']\n",
    "\n",
    "pickle.dump(id_difficulty, open(join(base_new, 'id_difficulty.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "id_difficulty = pickle.load(\n",
    "        open(join(base_new, \"id_difficulty.pkl\"), \"rb\")\n",
    ")\n",
    "for patho, hadm_info in zip(['appendicitis', 'cholecystitis', 'pancreatitis', 'diverticulitis'],\n",
    "                            [app_hadm_info, cholec_hadm_info, pancr_hadm_info, divert_hadm_info]):\n",
    "    hadm_info_firstdiag = {}\n",
    "    for _id in id_difficulty[patho]['first_diag']:\n",
    "        hadm_info_firstdiag[_id] = hadm_info[_id]\n",
    "    pickle.dump(hadm_info_firstdiag, open(join(base_new, f\"{patho}_hadm_info_first_diag.pkl\"), \"wb\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.utils import load_hadm_from_file\n",
    "\n",
    "app_hadm_info                   = load_hadm_from_file('appendicitis_hadm_info', base_new)\n",
    "app_hadm_info_clean             = load_hadm_from_file('appendicitis_hadm_info_clean', base_new)\n",
    "app_hadm_info_firstdiag         = load_hadm_from_file('appendicitis_hadm_info_first_diag', base_new)\n",
    "\n",
    "cholec_hadm_info                = load_hadm_from_file('cholecystitis_hadm_info', base_new)\n",
    "cholec_hadm_info_clean          = load_hadm_from_file('cholecystitis_hadm_info_clean', base_new)\n",
    "cholec_hadm_info_firstdiag      = load_hadm_from_file('cholecystitis_hadm_info_first_diag', base_new)\n",
    "\n",
    "pancr_hadm_info                 = load_hadm_from_file('pancreatitis_hadm_info', base_new)\n",
    "pancr_hadm_info_clean           = load_hadm_from_file('pancreatitis_hadm_info_clean', base_new)\n",
    "pancr_hadm_info_firstdiag       = load_hadm_from_file('pancreatitis_hadm_info_first_diag', base_new)\n",
    "\n",
    "divert_hadm_info                = load_hadm_from_file('diverticulitis_hadm_info', base_new)\n",
    "divert_hadm_info_clean          = load_hadm_from_file('diverticulitis_hadm_info_clean', base_new)\n",
    "divert_hadm_info_firstdiag      = load_hadm_from_file('diverticulitis_hadm_info_first_diag', base_new)\n",
    "\n",
    "app_hadm_ids = list(app_hadm_info_firstdiag.keys())\n",
    "cholec_hadm_ids = list(cholec_hadm_info_firstdiag.keys())\n",
    "pancr_hadm_ids = list(pancr_hadm_info_firstdiag.keys())\n",
    "divert_hadm_ids = list(divert_hadm_info_firstdiag.keys())\n",
    "\n",
    "import pickle\n",
    "id_difficulty = pickle.load(\n",
    "        open(join(base_new, \"id_difficulty.pkl\"), \"rb\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(app_hadm_info)} appendicitis patients\")\n",
    "print(f\"There are {len(cholec_hadm_info)} cholecystitis patients\")\n",
    "print(f\"There are {len(pancr_hadm_info)} pancreatitis patients\")\n",
    "print(f\"There are {len(divert_hadm_info)} diverticulitis patients\")\n",
    "print(f\"There are {len(app_hadm_info) + len(cholec_hadm_info) + len(pancr_hadm_info) + len(divert_hadm_info)} patients\")\n",
    "print('---')\n",
    "\n",
    "print(f\"There are {len(app_hadm_info_clean)} appendicitis patients with clean data\")\n",
    "print(f\"There are {len(cholec_hadm_info_clean)} cholecystitis patients with clean data\")\n",
    "print(f\"There are {len(pancr_hadm_info_clean)} pancreatitis patients with clean data\")\n",
    "print(f\"There are {len(divert_hadm_info_clean)} diverticulitis patients with clean data\")\n",
    "print(f\"There are {len(app_hadm_info_clean) + len(cholec_hadm_info_clean) + len(pancr_hadm_info_clean) + len(divert_hadm_info_clean)} patients with clean data\")\n",
    "print('---')\n",
    "\n",
    "print(f\"There are {len(app_hadm_info_firstdiag)} appendicitis patients with first diagnosis\")\n",
    "print(f\"There are {len(cholec_hadm_info_firstdiag)} cholecystitis patients with first diagnosis\")\n",
    "print(f\"There are {len(pancr_hadm_info_firstdiag)} pancreatitis patients with first diagnosis\")\n",
    "print(f\"There are {len(divert_hadm_info_firstdiag)} diverticulitis patients with first diagnosis\")\n",
    "print(f\"There are {len(app_hadm_info_firstdiag) + len(cholec_hadm_info_firstdiag) + len(pancr_hadm_info_firstdiag) + len(divert_hadm_info_firstdiag)} patients with first diagnosis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the dataset for physionet upload and sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(hadm_info, filename, fields):\n",
    "    with open(join(base_new, filename), 'a') as f:\n",
    "        for _id in hadm_info.keys():\n",
    "            f.write(f'{_id},\"')\n",
    "            # Replace internal double quotes with two double quotes\n",
    "            f.write('\",\"'.join([str(hadm_info[_id][field]).replace('\"', '\"\"').strip() for field in fields]))\n",
    "            f.write('\"\\n')\n",
    "\n",
    "with open(join(base_new, 'history_of_present_illness.csv'), \"w\") as f:\n",
    "    f.write('hadm_id,hpi\\n')\n",
    "\n",
    "with open(join(base_new, 'physical_examination.csv'), \"w\") as f:\n",
    "    f.write('hadm_id,pe\\n')\n",
    "\n",
    "with open(join(base_new, 'laboratory_tests.csv'), 'w') as f:\n",
    "    f.write('hadm_id,itemid,valuestr,ref_range_lower,ref_range_upper\\n')\n",
    "\n",
    "with open(join(base_new, 'microbiology.csv'), 'w') as f:\n",
    "    f.write('hadm_id,test_itemid,valuestr,spec_itemid\\n')\n",
    "\n",
    "with open(join(base_new, 'radiology_reports.csv'), 'w') as f:\n",
    "        f.write('hadm_id,note_id,modality,region,exam_name,text\\n')\n",
    "\n",
    "with open(join(base_new, 'discharge_diagnosis.csv'), \"w\") as f:\n",
    "    f.write('hadm_id,discharge_diagnosis\\n')\n",
    "\n",
    "with open(join(base_new, 'icd_diagnosis.csv'), 'w') as f:\n",
    "    f.write('hadm_id,icd_diagnosis\\n')\n",
    "\n",
    "with open(join(base_new, 'discharge_procedures.csv'), 'w') as f:\n",
    "    f.write('hadm_id,discharge_procedure\\n')\n",
    "\n",
    "with open(join(base_new, 'icd_procedures.csv'), 'w') as f:\n",
    "    f.write('hadm_id,icd_code,icd_version,icd_title\\n')\n",
    "    \n",
    "for hadm_info in [app_hadm_info_firstdiag, cholec_hadm_info_firstdiag, pancr_hadm_info_firstdiag, divert_hadm_info_firstdiag]:\n",
    "    fields = [\"Patient History\"]\n",
    "    write_csv(hadm_info, 'history_of_present_illness.csv', fields)\n",
    "\n",
    "    fields = [\"Physical Examination\"]    \n",
    "    write_csv(hadm_info, 'physical_examination.csv', fields)\n",
    "\n",
    "    with open(join(base_new, 'laboratory_tests.csv'), 'a') as f:\n",
    "        for _id in hadm_info.keys():\n",
    "            for itemid, value in hadm_info[_id][\"Laboratory Tests\"].items():\n",
    "                rr_lower = hadm_info[_id][\"Reference Range Lower\"][itemid]\n",
    "                rr_upper = hadm_info[_id][\"Reference Range Upper\"][itemid]\n",
    "                if pd.isna(rr_lower):\n",
    "                    rr_lower = ''\n",
    "                if pd.isna(rr_upper):\n",
    "                    rr_upper = ''\n",
    "                value = value.replace('\"', '\"\"')\n",
    "                f.write(f'{_id},{itemid},\"{value}\",{rr_lower},{rr_upper}\\n')\n",
    "\n",
    "    with open(join(base_new, 'microbiology.csv'), 'a') as f:\n",
    "        for _id in hadm_info.keys():\n",
    "            for itemid, value in hadm_info[_id][\"Microbiology\"].items():\n",
    "                value = value.replace('\"', '\"\"')\n",
    "                f.write(f'{_id},{itemid},\"{value.strip()}\",{hadm_info[_id][\"Microbiology Spec\"][itemid]}\\n')\n",
    "\n",
    "    with open(join(base_new, 'radiology_reports.csv'), 'a') as f:\n",
    "        for _id in hadm_info.keys():\n",
    "            for item in hadm_info[_id][\"Radiology\"]:\n",
    "                report = item[\"Report\"].replace('\"', '\"\"')\n",
    "                f.write(f'{_id},{item[\"Note ID\"]},\"{item[\"Modality\"]}\",\"{item[\"Region\"]}\",\"{item[\"Exam Name\"]}\",\"{report}\"\\n')\n",
    "\n",
    "    fields = [\"Discharge Diagnosis\"]    \n",
    "    write_csv(hadm_info, 'discharge_diagnosis.csv', fields)\n",
    "\n",
    "    with open(join(base_new, 'icd_diagnosis.csv'), 'a') as f:\n",
    "        for _id in hadm_info.keys():\n",
    "            for diagnosis in hadm_info[_id][\"ICD Diagnosis\"]:\n",
    "                diagnosis = diagnosis.replace('\"', '\"\"')\n",
    "                f.write(f'{_id},\"{diagnosis}\"\\n')\n",
    "        \n",
    "    with open(join(base_new, 'discharge_procedures.csv'), 'a') as f:\n",
    "        for _id in hadm_info.keys():\n",
    "            for procedure in hadm_info[_id][\"Procedures Discharge\"]:\n",
    "                procedure = procedure.replace('\"', '\"\"')\n",
    "                if procedure.lower() == \"none\" or procedure == \"___\" or procedure.lower() == \"n/a\" or len(procedure) == 1:\n",
    "                    continue\n",
    "                f.write(f'{_id},\"{procedure}\"\\n')\n",
    "\n",
    "    with open(join(base_new, 'icd_procedures.csv'), 'a') as f:\n",
    "        for _id in hadm_info.keys():\n",
    "            for indx, procedure_code in enumerate(hadm_info[_id][\"Procedures ICD9\"]):\n",
    "                procedure = hadm_info[_id][\"Procedures ICD9 Title\"][indx]\n",
    "                procedure = procedure.replace('\"', '\"\"')\n",
    "                f.write(f'{_id},{procedure_code},\"{procedure}\",9\\n')\n",
    "            for indx, procedure_code in enumerate(hadm_info[_id][\"Procedures ICD10\"]):\n",
    "                procedure = hadm_info[_id][\"Procedures ICD10 Title\"][indx]\n",
    "                procedure = procedure.replace('\"', '\"\"')\n",
    "                f.write(f'{_id},{procedure_code},\"{procedure}\",10\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.labs import generate_lab_test_mapping\n",
    "\n",
    "MIMIC_hosp_base = \"\"\n",
    "\n",
    "generate_lab_test_mapping(MIMIC_hosp_base)\n",
    "\n",
    "lab_test_mapping_df = pickle.load(open(join(MIMIC_hosp_base,'lab_test_mapping.pkl'), 'rb'))\n",
    "lab_test_mapping_df.to_csv(join(base_new, 'lab_test_mapping.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert physionet dataset back into project format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pickle\n",
    "\n",
    "base_new = \"./hosp\"\n",
    "lab_test_mapping_df = pd.read_csv(join(base_new, 'lab_test_mapping.csv'))\n",
    "lab_test_mapping_df['corresponding_ids'] = lab_test_mapping_df['corresponding_ids'].apply(ast.literal_eval)\n",
    "lab_test_mapping_df['corresponding_ids'] = lab_test_mapping_df['corresponding_ids'].apply(lambda x: [int(i) for i in x])\n",
    "pickle.dump(lab_test_mapping_df, open(join(base_new, 'lab_test_mapping.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join\n",
    "\n",
    "def update_hadm(base_new, filename, hadm_info, key, hadm_name, _list=False):\n",
    "    df = pd.read_csv(join(base_new, filename))\n",
    "    for _, row in df.iterrows():\n",
    "        _id = row['hadm_id']\n",
    "        if _list:\n",
    "            if hadm_name not in hadm_info[_id]:\n",
    "                hadm_info[_id][hadm_name] = []\n",
    "            hadm_info[_id][hadm_name].append(row[key])\n",
    "        # For single value fields\n",
    "        else:\n",
    "            hadm_info[_id][hadm_name] = row[key]\n",
    "    return hadm_info\n",
    "\n",
    "hadm_info = {}\n",
    "\n",
    "# Create entries for all hadm_ids\n",
    "hpi_df = pd.read_csv(join(base_new, 'history_of_present_illness.csv'))\n",
    "hadm_ids = hpi_df[\"hadm_id\"].to_list()\n",
    "for _id in hadm_ids:\n",
    "    hadm_info[_id] = {}\n",
    "\n",
    "hadm_info = update_hadm(base_new, 'history_of_present_illness.csv', hadm_info, 'hpi', 'Patient History')\n",
    "\n",
    "hadm_info = update_hadm(base_new, 'physical_examination.csv', hadm_info, 'pe', 'Physical Examination')\n",
    "\n",
    "lab_events_df = pd.read_csv(join(base_new, 'laboratory_tests.csv'))\n",
    "for _, row in lab_events_df.iterrows():\n",
    "    _id = row['hadm_id']\n",
    "    if \"Laboratory Tests\" not in hadm_info[_id]:\n",
    "        hadm_info[_id][\"Laboratory Tests\"] = {}\n",
    "        hadm_info[_id][\"Reference Range Lower\"] = {}\n",
    "        hadm_info[_id][\"Reference Range Upper\"] = {}\n",
    "    hadm_info[_id][\"Laboratory Tests\"][row['itemid']] = row['valuestr']\n",
    "    hadm_info[_id][\"Reference Range Lower\"][row['itemid']] = row['ref_range_lower']\n",
    "    hadm_info[_id][\"Reference Range Upper\"][row['itemid']] = row['ref_range_upper']\n",
    "\n",
    "microbiology_df = pd.read_csv(join(base_new, 'microbiology.csv'))\n",
    "for _, row in microbiology_df.iterrows():\n",
    "    _id = row['hadm_id']\n",
    "    if \"Microbiology\" not in hadm_info[_id]:\n",
    "        hadm_info[_id][\"Microbiology\"] = {}\n",
    "        hadm_info[_id][\"Microbiology Spec\"] = {}\n",
    "    hadm_info[_id][\"Microbiology\"][row['test_itemid']] = row['valuestr']\n",
    "    hadm_info[_id][\"Microbiology Spec\"][row['test_itemid']] = row['spec_itemid']\n",
    "\n",
    "radiology_df = pd.read_csv(join(base_new, 'radiology_reports.csv'))\n",
    "for _, row in radiology_df.iterrows():\n",
    "    _id = row['hadm_id']\n",
    "    if \"Radiology\" not in hadm_info[_id]:\n",
    "        hadm_info[_id][\"Radiology\"] = []\n",
    "    hadm_info[_id][\"Radiology\"].append({\"Note ID\": row['note_id'], \"Modality\": row['modality'], \"Region\": row['region'], \"Exam Name\": row['exam_name'], \"Report\": row['text']})\n",
    "\n",
    "hadm_info = update_hadm(base_new, 'discharge_diagnosis.csv', hadm_info, 'discharge_diagnosis', 'Discharge Diagnosis')\n",
    "\n",
    "hadm_info = update_hadm(base_new, 'icd_diagnosis.csv', hadm_info, 'icd_diagnosis', 'ICD Diagnosis', _list=True)\n",
    "\n",
    "hadm_info = update_hadm(base_new, 'discharge_procedures.csv', hadm_info, 'discharge_procedure', 'Procedures Discharge', _list=True)\n",
    "\n",
    "icd_procedures_df = pd.read_csv(join(base_new, 'icd_procedures.csv'))\n",
    "for _, row in icd_procedures_df.iterrows():\n",
    "    _id = row['hadm_id']\n",
    "    if \"Procedures ICD9\" not in hadm_info[_id]:\n",
    "        hadm_info[_id][\"Procedures ICD9\"] = []\n",
    "        hadm_info[_id][\"Procedures ICD9 Title\"] = []\n",
    "        hadm_info[_id][\"Procedures ICD10\"] = []\n",
    "        hadm_info[_id][\"Procedures ICD10 Title\"] = []\n",
    "    if row['icd_version'] == 9:\n",
    "        hadm_info[_id][\"Procedures ICD9\"].append(row['icd_code'])\n",
    "        hadm_info[_id][\"Procedures ICD9 Title\"].append(row['icd_title'])\n",
    "    else:\n",
    "        hadm_info[_id][\"Procedures ICD10\"].append(row['icd_code'])\n",
    "        hadm_info[_id][\"Procedures ICD10 Title\"].append(row['icd_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.nlp import extract_primary_diagnosis\n",
    "\n",
    "patho_ids = {\"appendicitis\": [], \"cholecystitis\": [], \"pancreatitis\": [], \"diverticulitis\": []}\n",
    "\n",
    "for _id, hadm in hadm_info.items():\n",
    "    possible_patho = \"\"\n",
    "    possible_patho_index = float(\"Inf\")\n",
    "    for patho in patho_ids.keys():\n",
    "        primary_diag = extract_primary_diagnosis(hadm[\"Discharge Diagnosis\"].lower())\n",
    "        if patho in primary_diag.lower():\n",
    "            new_patho_index = primary_diag.lower().find(patho)\n",
    "            if new_patho_index < possible_patho_index:\n",
    "                # Sanity check\n",
    "                if possible_patho:\n",
    "                    for patho_hadm_info, fd_hadm_info in zip([\"appendicitis\",\"diverticulitis\",\"cholecystitis\",\"pancreatitis\"],[app_hadm_info_firstdiag, cholec_hadm_info_firstdiag, pancr_hadm_info_firstdiag, divert_hadm_info_firstdiag]):\n",
    "                        if _id in fd_hadm_info:\n",
    "                            print(patho_hadm_info)\n",
    "                    print(_id)\n",
    "                    print(f'Found multiple pathologies: {possible_patho} and {patho}')\n",
    "                    print(primary_diag)\n",
    "                    print(\"-----\")\n",
    "                possible_patho = patho\n",
    "                possible_patho_index = new_patho_index\n",
    "    # Sanity check\n",
    "    if not possible_patho or possible_patho == \"\":\n",
    "        print(_id)\n",
    "        print(f'Could not find pathology in {primary_diag}')\n",
    "        print(\"-----\")\n",
    "    patho_ids[possible_patho].append(_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "for key in patho_ids.keys():\n",
    "    print(f'{key}: {len(patho_ids[key])}')\n",
    "print(f'Total: {sum([len(patho_ids[key]) for key in patho_ids.keys()])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_hadm_info_firstdiag = {}\n",
    "cholec_hadm_info_firstdiag = {}\n",
    "pancr_hadm_info_firstdiag = {}\n",
    "divert_hadm_info_firstdiag = {}\n",
    "\n",
    "for _id in patho_ids[\"appendicitis\"]:\n",
    "    app_hadm_info_firstdiag[_id] = hadm_info[_id]\n",
    "\n",
    "for _id in patho_ids[\"cholecystitis\"]:\n",
    "    cholec_hadm_info_firstdiag[_id] = hadm_info[_id]\n",
    "\n",
    "for _id in patho_ids[\"diverticulitis\"]:\n",
    "    divert_hadm_info_firstdiag[_id] = hadm_info[_id]\n",
    "\n",
    "for _id in patho_ids[\"pancreatitis\"]:\n",
    "    pancr_hadm_info_firstdiag[_id] = hadm_info[_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.utils import write_hadm_to_file\n",
    "\n",
    "write_hadm_to_file(app_hadm_info_firstdiag, 'appendicitis_hadm_info_first_diag', base_new)\n",
    "write_hadm_to_file(cholec_hadm_info_firstdiag, 'cholecystitis_hadm_info_first_diag', base_new)\n",
    "write_hadm_to_file(pancr_hadm_info_firstdiag, 'pancreatitis_hadm_info_first_diag', base_new)\n",
    "write_hadm_to_file(divert_hadm_info_firstdiag, 'diverticulitis_hadm_info_first_diag', base_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lab Events and Radiology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_events_df = pd.read_csv(join(base_mimic, 'hosp', 'ClinicalBenchmark', 'labevents.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average number of lab_events per hadm_id\n",
    "lab_events_subset = lab_events_df[lab_events_df['hadm_id'].isin(app_hadm_ids) | lab_events_df['hadm_id'].isin(cholec_hadm_ids) | lab_events_df['hadm_id'].isin(pancr_hadm_ids) | lab_events_df['hadm_id'].isin(divert_hadm_ids)]\n",
    "lab_events_subset.groupby('hadm_id').count().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiology_report_df = pd.read_csv(join(base_mimic, 'hosp', 'ClinicalBenchmark', 'radiology_reports.csv'))\n",
    "radiology_report_details_df = pd.read_csv(join(base_mimic, 'hosp', 'ClinicalBenchmark', 'radiology_report_details.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average number of radiology reports per hadm_id\n",
    "radiology_report_subset = radiology_report_df[radiology_report_df['hadm_id'].isin(app_hadm_ids) | radiology_report_df['hadm_id'].isin(cholec_hadm_ids) | radiology_report_df['hadm_id'].isin(pancr_hadm_ids) | radiology_report_df['hadm_id'].isin(divert_hadm_ids)]\n",
    "radiology_report_subset.groupby('hadm_id').count().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dilated Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "context = {}\n",
    "actions = ['dilat', 'enlarg', 'perforat', 'rupt', 'distend', 'fluid-filled', 'fluid filled', 'fluid collection']\n",
    "for _id in app_hadm_info_firstdiag:\n",
    "    hadm = app_hadm_info_firstdiag[_id]\n",
    "    for rad in hadm['Radiology']:\n",
    "        report = ' '.join(rad['Report'].split('\\n'))\n",
    "        sentences = report.split('. ')\n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.lower()\n",
    "            if 'appendi' in sentence and any([action in sentence for action in actions]):\n",
    "                context[_id] = sentence\n",
    "                count += 1\n",
    "    if _id not in context:\n",
    "        for rad in hadm['Radiology']:\n",
    "            print(rad['Report'])\n",
    "            print('---')\n",
    "print(len(context))\n",
    "print(len(app_hadm_info_firstdiag))\n",
    "display(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(id_difficulty['appendicitis']['first_diag']) + len(id_difficulty['pancreatitis']['first_diag']) + len(id_difficulty['cholecystitis']['first_diag']) + len(id_difficulty['diverticulitis']['first_diag']))\n",
    "unique_lab = set()\n",
    "unique_microbio = set()\n",
    "total_lab = 0\n",
    "total_microbio = 0\n",
    "radiology = {}\n",
    "unique_procedures = set()\n",
    "total_procedures = 0\n",
    "for patho, hadm_info in zip(['appendicitis', 'pancreatitis', 'cholecystitis', 'diverticulitis'], [app_hadm_info_firstdiag, pancr_hadm_info_firstdiag, cholec_hadm_info_firstdiag, divert_hadm_info_firstdiag]):\n",
    "    for patient_id in id_difficulty[patho]['first_diag']:\n",
    "        unique_lab.update(hadm_info[patient_id]['Laboratory Tests'].keys())\n",
    "        total_lab += len(hadm_info[patient_id]['Laboratory Tests'].keys())\n",
    "        unique_microbio.update(hadm_info[patient_id]['Microbiology'].keys())\n",
    "        total_microbio += len(hadm_info[patient_id]['Microbiology'].keys())\n",
    "        for r in hadm_info[patient_id]['Radiology']:\n",
    "            rad = r['Modality'] + ' ' + r['Region']\n",
    "            count = radiology.get(rad, 0)\n",
    "            radiology[rad] = count + 1\n",
    "        unique_procedures.update(hadm_info[patient_id]['Procedures ICD10'])\n",
    "        total_procedures += len(hadm_info[patient_id]['Procedures ICD10'])\n",
    "        unique_procedures.update(hadm_info[patient_id]['Procedures ICD9'])\n",
    "        total_procedures += len(hadm_info[patient_id]['Procedures ICD9'])\n",
    "    print(f'{patho} {len(id_difficulty[patho][\"first_diag\"])}')\n",
    "\n",
    "\n",
    "print(f'{len(unique_lab)} unique lab tests')\n",
    "print(f'{total_lab} total lab tests')\n",
    "\n",
    "print(f'{len(unique_microbio)} unique microbiology tests')\n",
    "print(f'{total_microbio} total microbiology tests')\n",
    "\n",
    "# sort radiology by count\n",
    "radiology = {k: v for k, v in sorted(radiology.items(), key=lambda item: item[1], reverse=True)}\n",
    "display(radiology)\n",
    "# print total radiology count\n",
    "total_rad = 0\n",
    "for rad, count in radiology.items():\n",
    "    total_rad += count\n",
    "print(f'{total_rad} total radiology reports')\n",
    "\n",
    "print(f'{len(unique_procedures)} unique procedures')\n",
    "print(f'{total_procedures} total procedures')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age and Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join\n",
    "MIMIC_hosp_base = ''\n",
    "admissions_df = pd.read_csv(join(MIMIC_hosp_base, 'admissions.csv'))\n",
    "patients_df = pd.read_csv(join(MIMIC_hosp_base, 'patients.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def calculate_statistics(data):\n",
    "    ages = [info['Age'] for info in data.values()]\n",
    "    genders = [info['Gender'] for info in data.values()]\n",
    "    races = [info['Race'] for info in data.values()]\n",
    "\n",
    "    age_median = pd.Series(ages).median()\n",
    "    age_min = min(ages)\n",
    "    age_max = max(ages)\n",
    "    gender_counts = Counter(genders)\n",
    "    race_counts = Counter(races)\n",
    "\n",
    "    # Convert counts to percentages\n",
    "    total = len(genders)\n",
    "    gender_percentages = {gender: count / total * 100 for gender, count in gender_counts.items()}\n",
    "    race_percentages = {race: count / total * 100 for race, count in race_counts.items()}\n",
    "\n",
    "    return age_median, (age_min, age_max), gender_percentages, race_percentages\n",
    "\n",
    "\n",
    "# Define the order of genders and races\n",
    "gender_order = ['F', 'M']\n",
    "race_order = ['WHITE', 'BLACK', 'HISPANIC', 'ASIAN', 'OTHER']\n",
    "\n",
    "race_dict = {\n",
    "    \"WHITE\": \"WHITE\",\n",
    "    \"BLACK\": \"BLACK\",\n",
    "    \"ASIAN\": \"ASIAN\",\n",
    "    \"HISPANIC\": \"HISPANIC\",\n",
    "    \"OTHER\": \"OTHER\",\n",
    "    \"HISPANIC OR LATINO\": \"HISPANIC\",\n",
    "    \"UNKNOWN\": \"OTHER\",\n",
    "    \"UNABLE TO OBTAIN\": \"OTHER\",\n",
    "    \"MULTIPLE RACE\": \"OTHER\",\n",
    "    \"SOUTH AMERICAN\": \"OTHER\",\n",
    "    \"AMERICAN INDIAN\": \"OTHER\",\n",
    "    \"PORTUGUESE\": \"OTHER\",\n",
    "    \"PATIENT DECLINED TO ANSWER\": \"OTHER\",\n",
    "}\n",
    "dataset_stats = {}\n",
    "\n",
    "full_dataset = [app_hadm_info_firstdiag, cholec_hadm_info_firstdiag, pancr_hadm_info_firstdiag, divert_hadm_info_firstdiag]\n",
    "\n",
    "app_hadm_info_dreval = {}\n",
    "cholec_hadm_info_dreval = {}\n",
    "pancr_hadm_info_dreval = {}\n",
    "divert_hadm_info_dreval = {}\n",
    "\n",
    "for _id in id_difficulty['appendicitis']['dr_eval']:\n",
    "    app_hadm_info_dreval[_id] = app_hadm_info_firstdiag[_id]\n",
    "\n",
    "for _id in id_difficulty['cholecystitis']['dr_eval']:\n",
    "    cholec_hadm_info_dreval[_id] = cholec_hadm_info_firstdiag[_id]\n",
    "\n",
    "for _id in id_difficulty['pancreatitis']['dr_eval']:\n",
    "    pancr_hadm_info_dreval[_id] = pancr_hadm_info_firstdiag[_id]\n",
    "\n",
    "for _id in id_difficulty['diverticulitis']['dr_eval']:\n",
    "    divert_hadm_info_dreval[_id] = divert_hadm_info_firstdiag[_id]\n",
    "\n",
    "dreval_dataset = [app_hadm_info_dreval, cholec_hadm_info_dreval, pancr_hadm_info_dreval, divert_hadm_info_dreval]\n",
    "    \n",
    "for group in [full_dataset, dreval_dataset]:\n",
    "    for patho, hadm_info in zip(['appendicitis', 'cholecystitis', 'pancreatitis', 'diverticulitis'],\n",
    "                                group):\n",
    "        dataset_stats[patho] = {}\n",
    "        for _id in hadm_info.keys():\n",
    "            subject_id = admissions_df.loc[admissions_df['hadm_id'] == _id, 'subject_id'].values[0]\n",
    "            anchor_age = patients_df.loc[patients_df['subject_id'] == subject_id, 'anchor_age'].values[0]\n",
    "            anchor_year = patients_df.loc[patients_df['subject_id'] == subject_id, 'anchor_year'].values[0]\n",
    "            admittime = admissions_df.loc[admissions_df['hadm_id'] == _id, 'admittime'].values[0]\n",
    "            admityear = admittime.split('-')[0]\n",
    "            hadm_age = int(admityear) - int(anchor_year) + int(anchor_age)\n",
    "            subject_gender = patients_df.loc[patients_df['subject_id'] == subject_id, 'gender'].values[0]\n",
    "            subject_race = race_dict[admissions_df.loc[admissions_df['hadm_id'] == _id, 'race'].values[0].split('-')[0].split('/')[0].strip()]\n",
    "            dataset_stats[patho][_id] = {\n",
    "                \"Age\": hadm_age,\n",
    "                \"Gender\": subject_gender,\n",
    "                \"Race\": subject_race\n",
    "            }\n",
    "        \n",
    "    # Calculate statistics for each disease\n",
    "    stats = {disease: calculate_statistics(data) for disease, data in dataset_stats.items()}\n",
    "\n",
    "    # Format for LaTeX table\n",
    "    for disease, (age_median, age_range, gender_percentages, race_percentages) in stats.items():\n",
    "        # Sort and format gender distribution\n",
    "        gender_distribution = \", \".join([f\"{gender} ({gender_percentages.get(gender, 0):.1f}\\%)\" for gender in gender_order])\n",
    "\n",
    "        # Sort and format race distribution\n",
    "        race_distribution = \" \\\\newline \".join([f\"{race} ({race_percentages.get(race, 0):.1f}\\%)\" for race in race_order])\n",
    "\n",
    "        print(f\"{disease.capitalize()} & {age_median} & {age_range[0]}-{age_range[1]} & {gender_distribution} & {race_distribution} \\\\\\\\ \\\\hline\")\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get diagnoses of patients with abdominal pain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find patients with abdominal pain in note text as chief complaint\n",
    "abd_complaint_df = discharge_df[discharge_df['text'].str.contains('chief complaint:\\s*abdominal pain', case=False)]\n",
    "\n",
    "# Get all unique diagnoses for these patients\n",
    "abd_complaint_diagnoses_df = diag_icd[diag_icd['hadm_id'].isin(abd_complaint_df['hadm_id'])]\n",
    "abd_complaint_diagnoses_df.value_counts('long_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abd_complaint_diagnoses_df[abd_complaint_diagnoses_df['long_title'].str.contains('Inguinal hernia, with obstruction')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataset of patients with abdominal pain but different final diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acute gastritis\n",
    "gastritis_hadm_ids = extract_hadm_ids('Acute gastritis', diag_icd, discharge_df, diag_counts=30, cc=10)\n",
    "gastritis_hadm_info, gastritis_hadm_info_clean = extract_info(gastritis_hadm_ids, 'gastritis', ['acute gastritis', 'gastritis'],\n",
    "                                                             discharge_df, admissions_df, transfers_df,lab_events_df, microbiology_df, radiology_report_df, radiology_report_details_df,\n",
    "                                                             diag_icd, procedures_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urinary tract infection\n",
    "uti_hadm_ids = extract_hadm_ids_filter_cc('Urinary tract infection', diag_icd, discharge_df, diag_counts=30, cc=10)\n",
    "uti_hadm_info, uti_hadm_info_clean = extract_info(uti_hadm_ids, 'urinary tract infection', ['urinary tract infection', 'uti'],\n",
    "                                                             discharge_df, admissions_df, transfers_df,lab_events_df, microbiology_df, radiology_report_df, radiology_report_details_df,\n",
    "                                                             diag_icd, procedures_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esophageal_reflux_hadm_ids = extract_hadm_ids_filter_cc('Esophageal reflux', diag_icd, discharge_df, diag_counts=30, cc=10)\n",
    "esophageal_reflux_hadm_info, esophageal_reflux_hadm_info_clean = extract_info(esophageal_reflux_hadm_ids, 'esophageal reflux', ['esophageal reflux'],\n",
    "                                                             discharge_df, admissions_df, transfers_df,lab_events_df, microbiology_df, radiology_report_df, radiology_report_details_df,\n",
    "                                                             diag_icd, procedures_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inguinal hernia, with obstruction\n",
    "hernia_hadm_ids = extract_hadm_ids('Inguinal hernia, with obstruction', diag_icd, discharge_df, diag_counts=30, cc=10)\n",
    "hernia_hadm_info, hernia_hadm_info_clean = extract_info(hernia_hadm_ids, 'hernia', [],\n",
    "                                                             discharge_df, admissions_df, transfers_df,lab_events_df, microbiology_df, radiology_report_df, radiology_report_details_df,\n",
    "                                                             diag_icd, procedures_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find patients in ED with abd pain but sent home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find patients with abdominal pain but sent home\n",
    "base_ed = join(base_mimic, 'ed')\n",
    "ed_diagnosis_df = pd.read_csv(join(base_ed, 'diagnosis.csv'))\n",
    "abdominal_pain_stays_ids = ed_diagnosis_df[ed_diagnosis_df['icd_code'].str.startswith('789') | ed_diagnosis_df['icd_code'].str.startswith('R10')]['stay_id'].unique()\n",
    "\n",
    "edstays_df = pd.read_csv(join(base_ed, 'edstays.csv'))\n",
    "abdominal_pain_stays_df = edstays_df[edstays_df['stay_id'].isin(abdominal_pain_stays_ids)]\n",
    "\n",
    "abd_pain_home_stay_ids = abdominal_pain_stays_df[abdominal_pain_stays_df['disposition']=='HOME']['stay_id']\n",
    "\n",
    "print('{} patients had abdominal pain but were sent home'.format(abdominal_pain_stays_df[abdominal_pain_stays_df['disposition']=='HOME']['stay_id'].nunique()))\n",
    "\n",
    "# Find supplementary info for patients with abdominal pain but sent home\n",
    "triage_df = pd.read_csv(join(base_ed, 'triage.csv'))\n",
    "triage_df = triage_df[triage_df['stay_id'].isin(abd_pain_home_stay_ids)]\n",
    "triage_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Lab Test Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.labs import generate_lab_test_mapping\n",
    "generate_lab_test_mapping()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selfsuper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a21be7fe9607dfe0c8ee311f8a5f36f314167f49973cd8e355a42459a56bba0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
